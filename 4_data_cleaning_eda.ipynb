{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.helper import reduce_mem_usage\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import numpy as np\n",
    "from scripts.helper import reduce_mem_usage, load_df\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "import seaborn as sns\n",
    "from pycaret.regression import *\n",
    "from pycaret.utils import check_metric\n",
    "from pycaret.datasets import get_data\n",
    "import pickle\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/shrunk_train_v2.csv', index_col=[0]) # Load shrunk train dataset and remove unnamed column\n",
    "dataset_test = pd.read_csv('data/shrunk_test_v2.csv', index_col=[0]) # Load shrunk test dataset and remove unnamed column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replaceing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if null values in dataset\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all null values in the dataset with zeros\n",
    "dataset.fillna({'totals.transactionRevenue': 0, \"trafficSource.referralPath\" : \"(not provided)\",\n",
    "          'totals.bounces': 0, 'totals.newVisits': 0, \"totals.pageviews\" : \"1\",\n",
    "          'trafficSource.isTrueDirect': False, \n",
    "          'trafficSource.adContent': 'None',\n",
    "            'trafficSource.keyword': '(not provided)'}, inplace=True)\n",
    "\n",
    "\n",
    "dataset_test.fillna({'totals.transactionRevenue': 0, \"trafficSource.referralPath\" : \"(not provided)\",\n",
    "          'totals.bounces': 0, 'totals.newVisits': 0, \"totals.pageviews\" : \"1\",\n",
    "          'trafficSource.isTrueDirect': False, \n",
    "          'trafficSource.adContent': 'None',\n",
    "            'trafficSource.keyword': '(not provided)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droping not important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= dataset.drop('geoNetwork.metro', axis = 1) # Too many missing values.\n",
    "\n",
    "dataset= dataset.drop('geoNetwork.continent', axis = 1) # Too many missing values.\n",
    "dataset= dataset.drop('geoNetwork.subContinent', axis = 1) # Too many missing values.\n",
    "dataset= dataset.drop('device.deviceCategory', axis = 1) # similar colmun as \"device.isMobile\".\n",
    "\n",
    "\n",
    "dataset_test= dataset_test.drop('geoNetwork.metro', axis = 1) # Too many missing values.\n",
    "\n",
    "dataset_test= dataset_test.drop('geoNetwork.continent', axis = 1) # Too many missing values.\n",
    "\n",
    "dataset_test= dataset_test.drop('geoNetwork.subContinent', axis = 1) # Too many missing values.\n",
    "\n",
    "dataset_test= dataset_test.drop('device.deviceCategory', axis = 1) # similar colmun as \"device.isMobile\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train data to a new .csv file\n",
    "path = 'data/cleaned_train_v2.csv'\n",
    "dataset.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data to a new .csv file\n",
    "path1 = 'data/cleaned_test_v2.csv'\n",
    "dataset_test.to_csv(path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with PISOX time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting POSIX data from visiStartTime column and replace it in date column\n",
    "dataset['date'] = pd.to_datetime(dataset['visitStartTime'], unit='s').dt.strftime('%Y-%m-%d')\n",
    "dataset = dataset.drop('visitStartTime', axis=1)\n",
    "\n",
    "dataset_test['date'] = pd.to_datetime(dataset_test['visitStartTime'], unit='s').dt.strftime('%Y-%m-%d')\n",
    "dataset_test = dataset_test.drop('visitStartTime', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = list()\n",
    "for i in dataset.columns:\n",
    "    if (dataset[i].dtype=='object' or dataset[i].dtype=='bool') and (not(i.startswith('total'))):\n",
    "        categorical_cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols.remove('fullVisitorId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = list()\n",
    "for i in dataset.columns:\n",
    "    if dataset[i].dtype not in ['object', 'bool']:\n",
    "        numerical_cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols.remove('visitId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols.remove('totals.transactionRevenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "# Listing categorical features in a variable and changing it to float.\n",
    "for feature in categorical_cols:\n",
    "    label_encoder = preprocessing.LabelEncoder() # initializing        label encoder object\n",
    "    label_encoder.fit(list(dataset[feature].values.astype('str')) + list(dataset_test[feature].values.astype('str')))\n",
    "\n",
    "# Fit with list of variables in that feature\n",
    "    dataset[feature] = label_encoder.transform(list(dataset[feature].values.astype('str'))) \n",
    "    dataset_test[feature] = label_encoder.transform(list(dataset_test[feature].values.astype('str'))) \n",
    "\n",
    "# Transforming that feature\n",
    "    print(\"for this feature : {0} label-encoding was done succesfully\".format(feature))\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Targets and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target for classification model\n",
    "reg_train = dataset[categorical_cols+numerical_cols]\n",
    "reg_train['Target'] = dataset['totals.transactionRevenue']\n",
    "reg_test = dataset_test[categorical_cols+numerical_cols]\n",
    "reg_test['Target'] = dataset_test['totals.transactionRevenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_transactionRevenue_zero = reg_train[reg_train['Target'] == 0].sample(frac=0.3, random_state=10)\n",
    "totals_transactionRevenue_nonzero = reg_train[reg_train['Target'] != 0]\n",
    "reg_train = pd.concat([totals_transactionRevenue_zero, totals_transactionRevenue_nonzero], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_train[\"Target\"] = reg_train[\"Target\"].apply(np.log1p)\n",
    "reg_test[\"Target\"] = reg_test[\"Target\"].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen = reg_test\n",
    "#data.reset_index(inplace=True, drop=True)\n",
    "#data_unseen.reset_index(inplace=True, drop=True)\n",
    "print('Data for Modeling: ' + str(reg_train.shape))\n",
    "print('Unseen Data For Predictions: ' + str(data_unseen.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_clf101 = setup(data = reg_train, target = 'Target', session_id=123, numeric_features = categorical_cols+numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Linear regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = create_model('lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(lr) # Plot residuals for Linear Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Error Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(lr, plot = 'error') # Plot prediction error for Linear Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(lr, plot='feature') # Plot feature importance for Linear Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test / hold-out Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Model for Deplyoment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr = finalize_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(final_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_predictions = predict_model(final_lr, data=data_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metric(unseen_predictions[\"Target\"], unseen_predictions.Label, 'RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final part - Creating submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Predicted Target Values of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_reg = unseen_predictions['Label']\n",
    "sub_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the result of prediction in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_reg.to_csv(\"models/sub_reg_base.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling back Regression Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_reg = pd.read_csv(\"models/sub_reg_base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = sub_reg.Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving FullvisitorID for creating submission file for aggregation per Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = dataset_test[\"fullVisitorId\"].values\n",
    "pred_target = pd.DataFrame({\"fullVisitorId\":test_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the part to get Predict Target value with fullVisitorId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing negative values\n",
    "pred_test[pred_test<0] = 0\n",
    "pred_target[\"PredictedLogRevenue\"] = np.expm1(pred_test)\n",
    "pred_target = pred_target.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission file ready below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_target.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n",
    "pred_target[\"PredictedLogRevenue\"] = np.log1p(pred_target[\"PredictedLogRevenue\"])\n",
    "pred_target.to_csv(\"model/submission_base.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final submission file\n",
    "pred_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  RMSE based on Stakeholders Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the part to get Actual Target with fullVisitorId to compare the previously Predict Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_target = pd.DataFrame({\"fullVisitorId\":test_id})\n",
    "act_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_target[\"Target_actual\"] = np.expm1(unseen_predictions['Target'])\n",
    "act_target = act_target.groupby(\"fullVisitorId\")[\"Target_actual\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_target.columns = [\"fullVisitorId\", \"Target_actual\"]\n",
    "act_target[\"Target_actual\"] = np.log1p(1+act_target[\"Target_actual\"])\n",
    "act_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the RMSE (based on Customer level)\n",
    "RMSE = np.sqrt((sum( (act_target['Target_actual'].values - pred_target['PredictedLogRevenue'].values) **2)) / len(act_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Your RMSE Score is: {RMSE}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0402135d49870b961f74d796f924ad426c34ba2a9a18d44bdd08100ee6884e7b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
