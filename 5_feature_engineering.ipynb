{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "pd.set_option(\"display.max_columns\", 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/cleaned_train_v2.csv', index_col=[0]) # Load cleaned train dataset and remove unnamed column\n",
    "\n",
    "dataset_test = pd.read_csv('data/cleaned_test_v2.csv', index_col=[0]) # Load cleaned test dataset and remove unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data types for cleaned train dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data types for cleaned train dataset\n",
    "dataset_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with PISOX time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting POSIX data from visiStartTime column and replace it in date column\n",
    "dataset['date'] = pd.to_datetime(dataset['visitStartTime'], unit='s').dt.strftime('%Y-%m-%d')\n",
    "dataset = dataset.drop('visitStartTime', axis=1)\n",
    "\n",
    "dataset_test['date'] = pd.to_datetime(dataset_test['visitStartTime'], unit='s').dt.strftime('%Y-%m-%d')\n",
    "dataset_test = dataset_test.drop('visitStartTime', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having separate columns for year, month and using new df\n",
    "dataset = dataset.assign(\n",
    "     Week = lambda x: pd.to_datetime(x['date']).dt.week,\n",
    "     Year = lambda x: pd.to_datetime(x['date']).dt.year,\n",
    "     Month = lambda x: pd.to_datetime(x['date']).dt.month\n",
    " )\n",
    "print(f'Start of year: {dataset.Year.min()}')\n",
    "print(f'Start of year: {dataset.Year.max()}')\n",
    "\n",
    "dataset_test = dataset_test.assign(\n",
    "     Week = lambda x: pd.to_datetime(x['date']).dt.week,\n",
    "     Year = lambda x: pd.to_datetime(x['date']).dt.year,\n",
    "     Month = lambda x: pd.to_datetime(x['date']).dt.month\n",
    " )\n",
    "print(f'Start of year: {dataset_test.Year.min()}')\n",
    "print(f'Start of year: {dataset_test.Year.max()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show head for cleaned train dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show head for cleaned test dataset\n",
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = list()\n",
    "for i in dataset.columns:\n",
    "    if (dataset[i].dtype=='object' or dataset[i].dtype=='bool') and (not(i.startswith('total'))):\n",
    "        categorical_cols.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Customers ID and Date from Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols.remove('fullVisitorId')\n",
    "categorical_cols.remove('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = list()\n",
    "for i in dataset.columns:\n",
    "    if dataset[i].dtype not in ['object', 'bool']:\n",
    "        numerical_cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Year, Visits ID and Transaction Revenue from Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols.remove('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols.remove('visitId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols.remove('totals.transactionRevenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding \"Average Hits per City\" and  \"Average Pageviews per City\" to the Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['hits_mean_city'] = dataset.groupby('geoNetwork.city')['totals.hits'].transform('mean').astype('int')\n",
    "\n",
    "dataset['pageviews_mean_city'] = dataset.groupby('geoNetwork.city')['totals.pageviews'].transform('mean').astype('int')\n",
    "\n",
    "dataset_test['hits_mean_city'] = dataset_test.groupby('geoNetwork.city')['totals.hits'].transform('mean').astype('int')\n",
    "\n",
    "dataset_test['pageviews_mean_city'] = dataset_test.groupby('geoNetwork.city')['totals.pageviews'].transform('mean').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols.append('hits_mean_city')\n",
    "numerical_cols.append('pageviews_mean_city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing numerical features in a variable and changing it to float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    dataset[col] = dataset[col].astype('float')\n",
    "    dataset_test[col] = dataset_test[col].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding the Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "# List categorical features in a variable and changing it to float\n",
    "for feature in categorical_cols:\n",
    "    label_encoder = preprocessing.LabelEncoder() # Initialize label encoder object\n",
    "    label_encoder.fit(list(dataset[feature].values.astype('str')) + list(dataset_test[feature].values.astype('str')))\n",
    "\n",
    "# Fit with list of variables in that feature\n",
    "    dataset[feature] = label_encoder.transform(list(dataset[feature].values.astype('str'))) \n",
    "    dataset_test[feature] = label_encoder.transform(list(dataset_test[feature].values.astype('str'))) \n",
    "\n",
    "# Transform the feature\n",
    "    print(\"for this feature : {0} label-encoding was done succesfully\".format(feature))\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Dataset Features which dont belong to the Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dataset.columns)-set(numerical_cols+categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Numerical and Categorical Features as Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrccl = np.array(numerical_cols)\n",
    "np.save(\"data/Numerical_Columns\", nrccl)\n",
    "ctgcl = np.array(categorical_cols)\n",
    "np.save(\"data/Categorical_Columns\", ctgcl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HeatMap for Features Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dum = dataset\n",
    "mask = np.triu(x_dum.corr())\n",
    "ax = sns.heatmap(round(x_dum.corr()*10,0), cmap=\"coolwarm\", annot=True, mask=mask  )\n",
    "x_dum.shape\n",
    "plt.savefig('images/correlogram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save featured train data to a new .csv file\n",
    "path = 'data/feat_train_v2.csv'\n",
    "dataset.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save featured test data to a new .csv file\n",
    "path1 = 'data/feat_test_v2.csv'\n",
    "dataset_test.to_csv(path1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0402135d49870b961f74d796f924ad426c34ba2a9a18d44bdd08100ee6884e7b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "242d87ea343fc6f7ba14f33c453c706201dc06349769965212905296918c8b6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
